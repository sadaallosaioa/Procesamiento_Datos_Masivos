{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1IgfFqqW6QyweOyksYGULv06Tj6JjHMXK","timestamp":1704564086118}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Instalaciones previas"],"metadata":{"id":"KMRAZ0Zk-AP7"}},{"cell_type":"markdown","source":["1. Instalamos java:"],"metadata":{"id":"4b0ZUUdrMNS7"}},{"cell_type":"code","source":["!apt-get install -y openjdk-11-jdk-headless -qq > /dev/null\n"],"metadata":{"id":"LlsrB96UMcwK","executionInfo":{"status":"ok","timestamp":1704713850719,"user_tz":-60,"elapsed":4367,"user":{"displayName":"Saioa Sada Allo","userId":"15281570099881323413"}}},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":["2. Descargamos Hadoop: (versión 3.3.5)\n"],"metadata":{"id":"qrkeXrnaNE93"}},{"cell_type":"code","source":["!wget https://downloads.apache.org/hadoop/common/hadoop-3.3.5/hadoop-3.3.5.tar.gz\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3mEOcMV6B1me","outputId":"43141275-154d-4c42-c058-f9a53e38c719","executionInfo":{"status":"ok","timestamp":1704713932523,"user_tz":-60,"elapsed":80340,"user":{"displayName":"Saioa Sada Allo","userId":"15281570099881323413"}}},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["--2024-01-08 11:37:32--  https://downloads.apache.org/hadoop/common/hadoop-3.3.5/hadoop-3.3.5.tar.gz\n","Resolving downloads.apache.org (downloads.apache.org)... 135.181.214.104, 88.99.95.219, 2a01:4f9:3a:2c57::2, ...\n","Connecting to downloads.apache.org (downloads.apache.org)|135.181.214.104|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 706533213 (674M) [application/x-gzip]\n","Saving to: ‘hadoop-3.3.5.tar.gz’\n","\n","hadoop-3.3.5.tar.gz 100%[===================>] 673.80M  14.1MB/s    in 80s     \n","\n","2024-01-08 11:38:52 (8.48 MB/s) - ‘hadoop-3.3.5.tar.gz’ saved [706533213/706533213]\n","\n"]}]},{"cell_type":"markdown","source":["3. Descomprimimimos y movemos a /usr/local:"],"metadata":{"id":"kq7_3TaKC_OV"}},{"cell_type":"code","source":["!tar -xzf hadoop-3.3.5.tar.gz\n","!mv hadoop-3.3.5/ /usr/local/\n"],"metadata":{"id":"c0iZr8s1DSn1","executionInfo":{"status":"ok","timestamp":1704713949141,"user_tz":-60,"elapsed":16628,"user":{"displayName":"Saioa Sada Allo","userId":"15281570099881323413"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["4. Creamos las variables de entorno de java y hadoop:"],"metadata":{"id":"li8yXQ_CDuuk"}},{"cell_type":"code","source":["import os\n","os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n","os.environ[\"HADOOP_HOME\"] = \"/usr/local/hadoop-3.3.5\"\n","os.environ[\"PATH\"] += os.pathsep + \"/usr/local/hadoop-3.3.5/bin\""],"metadata":{"id":"YEmkYNW-D1yY","executionInfo":{"status":"ok","timestamp":1704713949141,"user_tz":-60,"elapsed":21,"user":{"displayName":"Saioa Sada Allo","userId":"15281570099881323413"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["Para comprobar que la instalación funciona, ejecuto el programa wordcount:\n","- Creamos un archivo de entrada:"],"metadata":{"id":"y79QpySEEJO_"}},{"cell_type":"code","source":["%%bash\n","mkdir entradaWordCount\n","{\n"," echo \"Esto es una linea de prueba\"\n"," echo \"segunda linea de prueba\"\n"," echo \"Podemos incluir las líneas que queramos\"\n"," echo \"esta es la ultima linea\"\n","} > ./entradaWordCount/entrada-1"],"metadata":{"id":"MvgLtuz8EQp8","executionInfo":{"status":"ok","timestamp":1704628112000,"user_tz":-60,"elapsed":259,"user":{"displayName":"Saioa Sada Allo","userId":"15281570099881323413"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"2df3a2a8-8f6e-45f8-cc30-e9c7d5e38d22"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["mkdir: cannot create directory ‘entradaWordCount’: File exists\n"]}]},{"cell_type":"markdown","source":["...Ejecutamos:\n"],"metadata":{"id":"T6daHhJvEy5I"}},{"cell_type":"code","source":["!hadoop jar $HADOOP_HOME/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.3.5.jar wordcount ./entradaWordCount ./salidaWordCount"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZJqoSZ4wFUD9","executionInfo":{"status":"ok","timestamp":1704628118898,"user_tz":-60,"elapsed":2900,"user":{"displayName":"Saioa Sada Allo","userId":"15281570099881323413"}},"outputId":"90888112-fbf9-4b59-df6a-b64921c0db5b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-01-07 11:48:38,886 INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties\n","2024-01-07 11:48:39,133 INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).\n","2024-01-07 11:48:39,133 INFO impl.MetricsSystemImpl: JobTracker metrics system started\n","org.apache.hadoop.mapred.FileAlreadyExistsException: Output directory file:/content/salidaWordCount already exists\n","\tat org.apache.hadoop.mapreduce.lib.output.FileOutputFormat.checkOutputSpecs(FileOutputFormat.java:164)\n","\tat org.apache.hadoop.mapreduce.JobSubmitter.checkSpecs(JobSubmitter.java:277)\n","\tat org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:143)\n","\tat org.apache.hadoop.mapreduce.Job$11.run(Job.java:1678)\n","\tat org.apache.hadoop.mapreduce.Job$11.run(Job.java:1675)\n","\tat java.base/java.security.AccessController.doPrivileged(Native Method)\n","\tat java.base/javax.security.auth.Subject.doAs(Subject.java:423)\n","\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)\n","\tat org.apache.hadoop.mapreduce.Job.submit(Job.java:1675)\n","\tat org.apache.hadoop.mapreduce.Job.waitForCompletion(Job.java:1696)\n","\tat org.apache.hadoop.examples.WordCount.main(WordCount.java:87)\n","\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n","\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n","\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n","\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n","\tat org.apache.hadoop.util.ProgramDriver$ProgramDescription.invoke(ProgramDriver.java:71)\n","\tat org.apache.hadoop.util.ProgramDriver.run(ProgramDriver.java:144)\n","\tat org.apache.hadoop.examples.ExampleDriver.main(ExampleDriver.java:74)\n","\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n","\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n","\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n","\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n","\tat org.apache.hadoop.util.RunJar.run(RunJar.java:328)\n","\tat org.apache.hadoop.util.RunJar.main(RunJar.java:241)\n"]}]},{"cell_type":"markdown","source":["Y comprobamos la salida:"],"metadata":{"id":"Bps-fB66HK_B"}},{"cell_type":"code","source":["!cat ./salidaWordCount/*"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ll4OctFHHOlM","executionInfo":{"status":"ok","timestamp":1704626998592,"user_tz":-60,"elapsed":253,"user":{"displayName":"Saioa Sada Allo","userId":"15281570099881323413"}},"outputId":"38bebb50-45fb-4138-876f-302cae116028"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Esto\t1\n","Podemos\t1\n","de\t2\n","es\t2\n","esta\t1\n","incluir\t1\n","la\t1\n","las\t1\n","linea\t3\n","líneas\t1\n","prueba\t2\n","que\t1\n","queramos\t1\n","segunda\t1\n","ultima\t1\n","una\t1\n"]}]},{"cell_type":"markdown","source":["# Ejercicio 1\n","Subimos el archivo de los datos y los programas Mapper, Combiner y Reducer a collab:\n","(**Clicando en la parte izquierda** de archivos...)"],"metadata":{"id":"cL64rxyEIIxG"}},{"cell_type":"markdown","source":["1. Le damos permisos de ejecución a los programas Mapper, Combiner y Reducer_\n"],"metadata":{"id":"4GNw25Z_MdZJ"}},{"cell_type":"code","source":["!chmod u+x ./A1Ej1Map.py\n","!chmod u+x ./A1Ej1Com.py\n","!chmod u+x ./A1Ej1Red.py"],"metadata":{"id":"IDzxjOPVMg8f","executionInfo":{"status":"ok","timestamp":1704714690360,"user_tz":-60,"elapsed":696,"user":{"displayName":"Saioa Sada Allo","userId":"15281570099881323413"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["2. Ejecutamos el programa:"],"metadata":{"id":"Q10L_V1LPbz_"}},{"cell_type":"code","source":["!hadoop jar $HADOOP_HOME/share/hadoop/tools/lib/hadoop-streaming-3.3.5.jar \\\n","-files ./A1Ej1Map.py \\\n","-files ./A1Ej1Com.py \\\n","-files ./A1Ej1Red.py \\\n","-mapper ./A1Ej1Map.py \\\n","-combiner ./A1Ej1Com.py \\\n","-reducer ./A1Ej1Red.py \\\n","-input EntradaAct1Ej1.txt \\\n","-output ./salida1"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aVwsQAYDRhRo","executionInfo":{"status":"ok","timestamp":1704714712392,"user_tz":-60,"elapsed":8150,"user":{"displayName":"Saioa Sada Allo","userId":"15281570099881323413"}},"outputId":"7135d215-6ec0-4119-af78-4660cdbc5307"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-01-08 11:51:48,016 INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties\n","2024-01-08 11:51:48,311 INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).\n","2024-01-08 11:51:48,311 INFO impl.MetricsSystemImpl: JobTracker metrics system started\n","2024-01-08 11:51:48,344 WARN impl.MetricsSystemImpl: JobTracker metrics system already initialized!\n","2024-01-08 11:51:48,792 INFO mapred.FileInputFormat: Total input files to process : 1\n","2024-01-08 11:51:48,823 INFO mapreduce.JobSubmitter: number of splits:1\n","2024-01-08 11:51:49,344 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_local976884467_0001\n","2024-01-08 11:51:49,345 INFO mapreduce.JobSubmitter: Executing with tokens: []\n","2024-01-08 11:51:49,860 INFO mapred.LocalDistributedCacheManager: Localized file:/content/A1Ej1Map.py as file:/tmp/hadoop-root/mapred/local/job_local976884467_0001_988777fd-7e7a-435a-a1d3-e849cc8f5edc/A1Ej1Map.py\n","2024-01-08 11:51:49,992 INFO mapreduce.Job: The url to track the job: http://localhost:8080/\n","2024-01-08 11:51:49,994 INFO mapreduce.Job: Running job: job_local976884467_0001\n","2024-01-08 11:51:50,006 INFO mapred.LocalJobRunner: OutputCommitter set in config null\n","2024-01-08 11:51:50,009 INFO mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapred.FileOutputCommitter\n","2024-01-08 11:51:50,020 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n","2024-01-08 11:51:50,020 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n","2024-01-08 11:51:50,092 INFO mapred.LocalJobRunner: Waiting for map tasks\n","2024-01-08 11:51:50,098 INFO mapred.LocalJobRunner: Starting task: attempt_local976884467_0001_m_000000_0\n","2024-01-08 11:51:50,209 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n","2024-01-08 11:51:50,212 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n","2024-01-08 11:51:50,299 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n","2024-01-08 11:51:50,325 INFO mapred.MapTask: Processing split: file:/content/EntradaAct1Ej1.txt:0+85\n","2024-01-08 11:51:50,358 INFO mapred.MapTask: numReduceTasks: 1\n","2024-01-08 11:51:50,606 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n","2024-01-08 11:51:50,606 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n","2024-01-08 11:51:50,606 INFO mapred.MapTask: soft limit at 83886080\n","2024-01-08 11:51:50,606 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n","2024-01-08 11:51:50,606 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n","2024-01-08 11:51:50,612 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n","2024-01-08 11:51:50,628 INFO streaming.PipeMapRed: PipeMapRed exec [/content/././A1Ej1Map.py]\n","2024-01-08 11:51:50,635 INFO Configuration.deprecation: mapred.work.output.dir is deprecated. Instead, use mapreduce.task.output.dir\n","2024-01-08 11:51:50,638 INFO Configuration.deprecation: mapred.local.dir is deprecated. Instead, use mapreduce.cluster.local.dir\n","2024-01-08 11:51:50,638 INFO Configuration.deprecation: map.input.file is deprecated. Instead, use mapreduce.map.input.file\n","2024-01-08 11:51:50,639 INFO Configuration.deprecation: map.input.length is deprecated. Instead, use mapreduce.map.input.length\n","2024-01-08 11:51:50,640 INFO Configuration.deprecation: mapred.job.id is deprecated. Instead, use mapreduce.job.id\n","2024-01-08 11:51:50,640 INFO Configuration.deprecation: mapred.task.partition is deprecated. Instead, use mapreduce.task.partition\n","2024-01-08 11:51:50,642 INFO Configuration.deprecation: map.input.start is deprecated. Instead, use mapreduce.map.input.start\n","2024-01-08 11:51:50,642 INFO Configuration.deprecation: mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap\n","2024-01-08 11:51:50,643 INFO Configuration.deprecation: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id\n","2024-01-08 11:51:50,643 INFO Configuration.deprecation: mapred.tip.id is deprecated. Instead, use mapreduce.task.id\n","2024-01-08 11:51:50,644 INFO Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords\n","2024-01-08 11:51:50,645 INFO Configuration.deprecation: user.name is deprecated. Instead, use mapreduce.job.user.name\n","2024-01-08 11:51:50,667 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\n","2024-01-08 11:51:50,758 INFO streaming.PipeMapRed: Records R/W=5/1\n","2024-01-08 11:51:50,761 INFO streaming.PipeMapRed: MRErrorThread done\n","2024-01-08 11:51:50,762 INFO streaming.PipeMapRed: mapRedFinished\n","2024-01-08 11:51:50,770 INFO mapred.LocalJobRunner: \n","2024-01-08 11:51:50,770 INFO mapred.MapTask: Starting flush of map output\n","2024-01-08 11:51:50,770 INFO mapred.MapTask: Spilling map output\n","2024-01-08 11:51:50,770 INFO mapred.MapTask: bufstart = 0; bufend = 82; bufvoid = 104857600\n","2024-01-08 11:51:50,770 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214380(104857520); length = 17/6553600\n","2024-01-08 11:51:50,791 INFO streaming.PipeMapRed: PipeMapRed exec [/content/././A1Ej1Com.py]\n","2024-01-08 11:51:50,795 INFO Configuration.deprecation: mapred.skip.map.auto.incr.proc.count is deprecated. Instead, use mapreduce.map.skip.proc-count.auto-incr\n","2024-01-08 11:51:50,837 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\n","2024-01-08 11:51:50,915 INFO streaming.PipeMapRed: Records R/W=5/1\n","2024-01-08 11:51:50,922 INFO streaming.PipeMapRed: MRErrorThread done\n","2024-01-08 11:51:50,923 INFO streaming.PipeMapRed: mapRedFinished\n","2024-01-08 11:51:50,924 INFO mapred.MapTask: Finished spill 0\n","2024-01-08 11:51:50,940 INFO mapred.Task: Task:attempt_local976884467_0001_m_000000_0 is done. And is in the process of committing\n","2024-01-08 11:51:50,957 INFO mapred.LocalJobRunner: Records R/W=5/1\n","2024-01-08 11:51:50,957 INFO mapred.Task: Task 'attempt_local976884467_0001_m_000000_0' done.\n","2024-01-08 11:51:50,969 INFO mapred.Task: Final Counters for attempt_local976884467_0001_m_000000_0: Counters: 18\n","\tFile System Counters\n","\t\tFILE: Number of bytes read=141884\n","\t\tFILE: Number of bytes written=783637\n","\t\tFILE: Number of read operations=0\n","\t\tFILE: Number of large read operations=0\n","\t\tFILE: Number of write operations=0\n","\tMap-Reduce Framework\n","\t\tMap input records=5\n","\t\tMap output records=5\n","\t\tMap output bytes=82\n","\t\tMap output materialized bytes=74\n","\t\tInput split bytes=84\n","\t\tCombine input records=5\n","\t\tCombine output records=3\n","\t\tSpilled Records=3\n","\t\tFailed Shuffles=0\n","\t\tMerged Map outputs=0\n","\t\tGC time elapsed (ms)=0\n","\t\tTotal committed heap usage (bytes)=277872640\n","\tFile Input Format Counters \n","\t\tBytes Read=85\n","2024-01-08 11:51:50,976 INFO mapred.LocalJobRunner: Finishing task: attempt_local976884467_0001_m_000000_0\n","2024-01-08 11:51:50,977 INFO mapred.LocalJobRunner: map task executor complete.\n","2024-01-08 11:51:50,983 INFO mapred.LocalJobRunner: Waiting for reduce tasks\n","2024-01-08 11:51:50,993 INFO mapred.LocalJobRunner: Starting task: attempt_local976884467_0001_r_000000_0\n","2024-01-08 11:51:51,012 INFO mapreduce.Job: Job job_local976884467_0001 running in uber mode : false\n","2024-01-08 11:51:51,013 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n","2024-01-08 11:51:51,013 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n","2024-01-08 11:51:51,014 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n","2024-01-08 11:51:51,026 INFO mapreduce.Job:  map 100% reduce 0%\n","2024-01-08 11:51:51,027 INFO mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@583edf27\n","2024-01-08 11:51:51,041 WARN impl.MetricsSystemImpl: JobTracker metrics system already initialized!\n","2024-01-08 11:51:51,108 INFO reduce.MergeManagerImpl: MergerManager: memoryLimit=2382574336, maxSingleShuffleLimit=595643584, mergeThreshold=1572499072, ioSortFactor=10, memToMemMergeOutputsThreshold=10\n","2024-01-08 11:51:51,126 INFO reduce.EventFetcher: attempt_local976884467_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events\n","2024-01-08 11:51:51,245 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local976884467_0001_m_000000_0 decomp: 70 len: 74 to MEMORY\n","2024-01-08 11:51:51,260 INFO reduce.InMemoryMapOutput: Read 70 bytes from map-output for attempt_local976884467_0001_m_000000_0\n","2024-01-08 11:51:51,263 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 70, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->70\n","2024-01-08 11:51:51,273 INFO reduce.EventFetcher: EventFetcher is interrupted.. Returning\n","2024-01-08 11:51:51,275 INFO mapred.LocalJobRunner: 1 / 1 copied.\n","2024-01-08 11:51:51,275 INFO reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs\n","2024-01-08 11:51:51,289 INFO mapred.Merger: Merging 1 sorted segments\n","2024-01-08 11:51:51,290 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 54 bytes\n","2024-01-08 11:51:51,292 INFO reduce.MergeManagerImpl: Merged 1 segments, 70 bytes to disk to satisfy reduce memory limit\n","2024-01-08 11:51:51,302 INFO reduce.MergeManagerImpl: Merging 1 files, 74 bytes from disk\n","2024-01-08 11:51:51,303 INFO reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce\n","2024-01-08 11:51:51,304 INFO mapred.Merger: Merging 1 sorted segments\n","2024-01-08 11:51:51,308 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 54 bytes\n","2024-01-08 11:51:51,309 INFO mapred.LocalJobRunner: 1 / 1 copied.\n","2024-01-08 11:51:51,319 INFO streaming.PipeMapRed: PipeMapRed exec [/content/././A1Ej1Red.py]\n","2024-01-08 11:51:51,330 INFO Configuration.deprecation: mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address\n","2024-01-08 11:51:51,335 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps\n","2024-01-08 11:51:51,370 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\n","2024-01-08 11:51:51,488 INFO streaming.PipeMapRed: Records R/W=3/1\n","2024-01-08 11:51:51,502 INFO streaming.PipeMapRed: MRErrorThread done\n","2024-01-08 11:51:51,503 INFO streaming.PipeMapRed: mapRedFinished\n","2024-01-08 11:51:51,509 INFO mapred.Task: Task:attempt_local976884467_0001_r_000000_0 is done. And is in the process of committing\n","2024-01-08 11:51:51,511 INFO mapred.LocalJobRunner: 1 / 1 copied.\n","2024-01-08 11:51:51,511 INFO mapred.Task: Task attempt_local976884467_0001_r_000000_0 is allowed to commit now\n","2024-01-08 11:51:51,513 INFO output.FileOutputCommitter: Saved output of task 'attempt_local976884467_0001_r_000000_0' to file:/content/salida1\n","2024-01-08 11:51:51,521 INFO mapred.LocalJobRunner: Records R/W=3/1 > reduce\n","2024-01-08 11:51:51,521 INFO mapred.Task: Task 'attempt_local976884467_0001_r_000000_0' done.\n","2024-01-08 11:51:51,522 INFO mapred.Task: Final Counters for attempt_local976884467_0001_r_000000_0: Counters: 24\n","\tFile System Counters\n","\t\tFILE: Number of bytes read=142064\n","\t\tFILE: Number of bytes written=783781\n","\t\tFILE: Number of read operations=0\n","\t\tFILE: Number of large read operations=0\n","\t\tFILE: Number of write operations=0\n","\tMap-Reduce Framework\n","\t\tCombine input records=0\n","\t\tCombine output records=0\n","\t\tReduce input groups=3\n","\t\tReduce shuffle bytes=74\n","\t\tReduce input records=3\n","\t\tReduce output records=3\n","\t\tSpilled Records=3\n","\t\tShuffled Maps =1\n","\t\tFailed Shuffles=0\n","\t\tMerged Map outputs=1\n","\t\tGC time elapsed (ms)=0\n","\t\tTotal committed heap usage (bytes)=277872640\n","\tShuffle Errors\n","\t\tBAD_ID=0\n","\t\tCONNECTION=0\n","\t\tIO_ERROR=0\n","\t\tWRONG_LENGTH=0\n","\t\tWRONG_MAP=0\n","\t\tWRONG_REDUCE=0\n","\tFile Output Format Counters \n","\t\tBytes Written=70\n","2024-01-08 11:51:51,522 INFO mapred.LocalJobRunner: Finishing task: attempt_local976884467_0001_r_000000_0\n","2024-01-08 11:51:51,522 INFO mapred.LocalJobRunner: reduce task executor complete.\n","2024-01-08 11:51:52,029 INFO mapreduce.Job:  map 100% reduce 100%\n","2024-01-08 11:51:52,030 INFO mapreduce.Job: Job job_local976884467_0001 completed successfully\n","2024-01-08 11:51:52,058 INFO mapreduce.Job: Counters: 30\n","\tFile System Counters\n","\t\tFILE: Number of bytes read=283948\n","\t\tFILE: Number of bytes written=1567418\n","\t\tFILE: Number of read operations=0\n","\t\tFILE: Number of large read operations=0\n","\t\tFILE: Number of write operations=0\n","\tMap-Reduce Framework\n","\t\tMap input records=5\n","\t\tMap output records=5\n","\t\tMap output bytes=82\n","\t\tMap output materialized bytes=74\n","\t\tInput split bytes=84\n","\t\tCombine input records=5\n","\t\tCombine output records=3\n","\t\tReduce input groups=3\n","\t\tReduce shuffle bytes=74\n","\t\tReduce input records=3\n","\t\tReduce output records=3\n","\t\tSpilled Records=6\n","\t\tShuffled Maps =1\n","\t\tFailed Shuffles=0\n","\t\tMerged Map outputs=1\n","\t\tGC time elapsed (ms)=0\n","\t\tTotal committed heap usage (bytes)=555745280\n","\tShuffle Errors\n","\t\tBAD_ID=0\n","\t\tCONNECTION=0\n","\t\tIO_ERROR=0\n","\t\tWRONG_LENGTH=0\n","\t\tWRONG_MAP=0\n","\t\tWRONG_REDUCE=0\n","\tFile Input Format Counters \n","\t\tBytes Read=85\n","\tFile Output Format Counters \n","\t\tBytes Written=70\n","2024-01-08 11:51:52,061 INFO streaming.StreamJob: Output directory: ./salida1\n"]}]},{"cell_type":"markdown","source":[],"metadata":{"id":"jGM4eT3aiRP8"}},{"cell_type":"code","source":["!cat ./salida1/*"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hlnffE2MRp6s","executionInfo":{"status":"ok","timestamp":1704715346773,"user_tz":-60,"elapsed":258,"user":{"displayName":"Saioa Sada Allo","userId":"15281570099881323413"}},"outputId":"12aacd6e-3f25-46c5-869a-d78c88c501cd"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Alice;Tienda1;75.0\t\n","Alice;Tienda2;20.0\t\n","Bob;Tienda1;25.0\t\n"]}]},{"cell_type":"markdown","source":["Ahora con un archivo mayor"],"metadata":{"id":"suvX1q6i_k1u"}},{"cell_type":"code","source":["!hadoop jar $HADOOP_HOME/share/hadoop/tools/lib/hadoop-streaming-3.3.5.jar \\\n","-files ./A1Ej1Map.py \\\n","-files ./A1Ej1Com.py \\\n","-files ./A1Ej1Red.py \\\n","-mapper ./A1Ej1Map.py \\\n","-combiner ./A1Ej1Com.py \\\n","-reducer ./A1Ej1Red.py \\\n","-input EntradaGrandeAct1Ej1.txt \\\n","-output ./salida2"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Tbw4twq6_ohM","executionInfo":{"status":"ok","timestamp":1704715376023,"user_tz":-60,"elapsed":7217,"user":{"displayName":"Saioa Sada Allo","userId":"15281570099881323413"}},"outputId":"9e3b3ae8-7513-40dc-9a80-f3b88a374761"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-01-08 12:02:51,624 INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties\n","2024-01-08 12:02:51,853 INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).\n","2024-01-08 12:02:51,853 INFO impl.MetricsSystemImpl: JobTracker metrics system started\n","2024-01-08 12:02:51,884 WARN impl.MetricsSystemImpl: JobTracker metrics system already initialized!\n","2024-01-08 12:02:52,297 INFO mapred.FileInputFormat: Total input files to process : 1\n","2024-01-08 12:02:52,334 INFO mapreduce.JobSubmitter: number of splits:1\n","2024-01-08 12:02:52,737 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_local1376991955_0001\n","2024-01-08 12:02:52,737 INFO mapreduce.JobSubmitter: Executing with tokens: []\n","2024-01-08 12:02:53,327 INFO mapred.LocalDistributedCacheManager: Localized file:/content/A1Ej1Map.py as file:/tmp/hadoop-root/mapred/local/job_local1376991955_0001_4015ba17-7470-4461-928f-eda79e7a678f/A1Ej1Map.py\n","2024-01-08 12:02:53,553 INFO mapreduce.Job: The url to track the job: http://localhost:8080/\n","2024-01-08 12:02:53,555 INFO mapreduce.Job: Running job: job_local1376991955_0001\n","2024-01-08 12:02:53,568 INFO mapred.LocalJobRunner: OutputCommitter set in config null\n","2024-01-08 12:02:53,571 INFO mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapred.FileOutputCommitter\n","2024-01-08 12:02:53,577 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n","2024-01-08 12:02:53,578 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n","2024-01-08 12:02:53,682 INFO mapred.LocalJobRunner: Waiting for map tasks\n","2024-01-08 12:02:53,688 INFO mapred.LocalJobRunner: Starting task: attempt_local1376991955_0001_m_000000_0\n","2024-01-08 12:02:53,771 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n","2024-01-08 12:02:53,773 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n","2024-01-08 12:02:53,829 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n","2024-01-08 12:02:53,860 INFO mapred.MapTask: Processing split: file:/content/EntradaGrandeAct1Ej1.txt:0+2546\n","2024-01-08 12:02:53,900 INFO mapred.MapTask: numReduceTasks: 1\n","2024-01-08 12:02:54,139 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n","2024-01-08 12:02:54,139 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n","2024-01-08 12:02:54,139 INFO mapred.MapTask: soft limit at 83886080\n","2024-01-08 12:02:54,139 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n","2024-01-08 12:02:54,139 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n","2024-01-08 12:02:54,147 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n","2024-01-08 12:02:54,161 INFO streaming.PipeMapRed: PipeMapRed exec [/content/././A1Ej1Map.py]\n","2024-01-08 12:02:54,183 INFO Configuration.deprecation: mapred.work.output.dir is deprecated. Instead, use mapreduce.task.output.dir\n","2024-01-08 12:02:54,184 INFO Configuration.deprecation: mapred.local.dir is deprecated. Instead, use mapreduce.cluster.local.dir\n","2024-01-08 12:02:54,187 INFO Configuration.deprecation: map.input.file is deprecated. Instead, use mapreduce.map.input.file\n","2024-01-08 12:02:54,188 INFO Configuration.deprecation: map.input.length is deprecated. Instead, use mapreduce.map.input.length\n","2024-01-08 12:02:54,189 INFO Configuration.deprecation: mapred.job.id is deprecated. Instead, use mapreduce.job.id\n","2024-01-08 12:02:54,189 INFO Configuration.deprecation: mapred.task.partition is deprecated. Instead, use mapreduce.task.partition\n","2024-01-08 12:02:54,199 INFO Configuration.deprecation: map.input.start is deprecated. Instead, use mapreduce.map.input.start\n","2024-01-08 12:02:54,200 INFO Configuration.deprecation: mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap\n","2024-01-08 12:02:54,200 INFO Configuration.deprecation: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id\n","2024-01-08 12:02:54,200 INFO Configuration.deprecation: mapred.tip.id is deprecated. Instead, use mapreduce.task.id\n","2024-01-08 12:02:54,201 INFO Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords\n","2024-01-08 12:02:54,211 INFO Configuration.deprecation: user.name is deprecated. Instead, use mapreduce.job.user.name\n","2024-01-08 12:02:54,262 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\n","2024-01-08 12:02:54,264 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\n","2024-01-08 12:02:54,268 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]\n","2024-01-08 12:02:54,333 INFO streaming.PipeMapRed: Records R/W=159/1\n","2024-01-08 12:02:54,354 INFO streaming.PipeMapRed: MRErrorThread done\n","2024-01-08 12:02:54,360 INFO streaming.PipeMapRed: mapRedFinished\n","2024-01-08 12:02:54,365 INFO mapred.LocalJobRunner: \n","2024-01-08 12:02:54,365 INFO mapred.MapTask: Starting flush of map output\n","2024-01-08 12:02:54,365 INFO mapred.MapTask: Spilling map output\n","2024-01-08 12:02:54,365 INFO mapred.MapTask: bufstart = 0; bufend = 2389; bufvoid = 104857600\n","2024-01-08 12:02:54,365 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26213764(104855056); length = 633/6553600\n","2024-01-08 12:02:54,411 INFO streaming.PipeMapRed: PipeMapRed exec [/content/././A1Ej1Com.py]\n","2024-01-08 12:02:54,416 INFO Configuration.deprecation: mapred.skip.map.auto.incr.proc.count is deprecated. Instead, use mapreduce.map.skip.proc-count.auto-incr\n","2024-01-08 12:02:54,461 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\n","2024-01-08 12:02:54,462 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\n","2024-01-08 12:02:54,463 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]\n","2024-01-08 12:02:54,519 INFO streaming.PipeMapRed: Records R/W=159/1\n","2024-01-08 12:02:54,527 INFO streaming.PipeMapRed: MRErrorThread done\n","2024-01-08 12:02:54,529 INFO streaming.PipeMapRed: mapRedFinished\n","2024-01-08 12:02:54,530 INFO mapred.MapTask: Finished spill 0\n","2024-01-08 12:02:54,567 INFO mapreduce.Job: Job job_local1376991955_0001 running in uber mode : false\n","2024-01-08 12:02:54,569 INFO mapreduce.Job:  map 0% reduce 0%\n","2024-01-08 12:02:54,579 INFO mapred.Task: Task:attempt_local1376991955_0001_m_000000_0 is done. And is in the process of committing\n","2024-01-08 12:02:54,588 INFO mapred.LocalJobRunner: Records R/W=159/1\n","2024-01-08 12:02:54,590 INFO mapred.Task: Task 'attempt_local1376991955_0001_m_000000_0' done.\n","2024-01-08 12:02:54,613 INFO mapred.Task: Final Counters for attempt_local1376991955_0001_m_000000_0: Counters: 18\n","\tFile System Counters\n","\t\tFILE: Number of bytes read=144353\n","\t\tFILE: Number of bytes written=786819\n","\t\tFILE: Number of read operations=0\n","\t\tFILE: Number of large read operations=0\n","\t\tFILE: Number of write operations=0\n","\tMap-Reduce Framework\n","\t\tMap input records=159\n","\t\tMap output records=159\n","\t\tMap output bytes=2389\n","\t\tMap output materialized bytes=123\n","\t\tInput split bytes=90\n","\t\tCombine input records=159\n","\t\tCombine output records=5\n","\t\tSpilled Records=5\n","\t\tFailed Shuffles=0\n","\t\tMerged Map outputs=0\n","\t\tGC time elapsed (ms)=0\n","\t\tTotal committed heap usage (bytes)=326107136\n","\tFile Input Format Counters \n","\t\tBytes Read=2546\n","2024-01-08 12:02:54,613 INFO mapred.LocalJobRunner: Finishing task: attempt_local1376991955_0001_m_000000_0\n","2024-01-08 12:02:54,613 INFO mapred.LocalJobRunner: map task executor complete.\n","2024-01-08 12:02:54,618 INFO mapred.LocalJobRunner: Waiting for reduce tasks\n","2024-01-08 12:02:54,627 INFO mapred.LocalJobRunner: Starting task: attempt_local1376991955_0001_r_000000_0\n","2024-01-08 12:02:54,654 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n","2024-01-08 12:02:54,654 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n","2024-01-08 12:02:54,664 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n","2024-01-08 12:02:54,674 INFO mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@6edb36df\n","2024-01-08 12:02:54,684 WARN impl.MetricsSystemImpl: JobTracker metrics system already initialized!\n","2024-01-08 12:02:54,746 INFO reduce.MergeManagerImpl: MergerManager: memoryLimit=2382574336, maxSingleShuffleLimit=595643584, mergeThreshold=1572499072, ioSortFactor=10, memToMemMergeOutputsThreshold=10\n","2024-01-08 12:02:54,773 INFO reduce.EventFetcher: attempt_local1376991955_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events\n","2024-01-08 12:02:54,871 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1376991955_0001_m_000000_0 decomp: 119 len: 123 to MEMORY\n","2024-01-08 12:02:54,886 INFO reduce.InMemoryMapOutput: Read 119 bytes from map-output for attempt_local1376991955_0001_m_000000_0\n","2024-01-08 12:02:54,891 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 119, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->119\n","2024-01-08 12:02:54,900 INFO reduce.EventFetcher: EventFetcher is interrupted.. Returning\n","2024-01-08 12:02:54,902 INFO mapred.LocalJobRunner: 1 / 1 copied.\n","2024-01-08 12:02:54,902 INFO reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs\n","2024-01-08 12:02:54,912 INFO mapred.Merger: Merging 1 sorted segments\n","2024-01-08 12:02:54,919 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 103 bytes\n","2024-01-08 12:02:54,921 INFO reduce.MergeManagerImpl: Merged 1 segments, 119 bytes to disk to satisfy reduce memory limit\n","2024-01-08 12:02:54,922 INFO reduce.MergeManagerImpl: Merging 1 files, 123 bytes from disk\n","2024-01-08 12:02:54,923 INFO reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce\n","2024-01-08 12:02:54,923 INFO mapred.Merger: Merging 1 sorted segments\n","2024-01-08 12:02:54,929 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 103 bytes\n","2024-01-08 12:02:54,931 INFO mapred.LocalJobRunner: 1 / 1 copied.\n","2024-01-08 12:02:54,955 INFO streaming.PipeMapRed: PipeMapRed exec [/content/././A1Ej1Red.py]\n","2024-01-08 12:02:54,959 INFO Configuration.deprecation: mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address\n","2024-01-08 12:02:54,962 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps\n","2024-01-08 12:02:55,005 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\n","2024-01-08 12:02:55,130 INFO streaming.PipeMapRed: Records R/W=5/1\n","2024-01-08 12:02:55,139 INFO streaming.PipeMapRed: MRErrorThread done\n","2024-01-08 12:02:55,147 INFO streaming.PipeMapRed: mapRedFinished\n","2024-01-08 12:02:55,149 INFO mapred.Task: Task:attempt_local1376991955_0001_r_000000_0 is done. And is in the process of committing\n","2024-01-08 12:02:55,151 INFO mapred.LocalJobRunner: 1 / 1 copied.\n","2024-01-08 12:02:55,151 INFO mapred.Task: Task attempt_local1376991955_0001_r_000000_0 is allowed to commit now\n","2024-01-08 12:02:55,156 INFO output.FileOutputCommitter: Saved output of task 'attempt_local1376991955_0001_r_000000_0' to file:/content/salida2\n","2024-01-08 12:02:55,161 INFO mapred.LocalJobRunner: Records R/W=5/1 > reduce\n","2024-01-08 12:02:55,161 INFO mapred.Task: Task 'attempt_local1376991955_0001_r_000000_0' done.\n","2024-01-08 12:02:55,163 INFO mapred.Task: Final Counters for attempt_local1376991955_0001_r_000000_0: Counters: 24\n","\tFile System Counters\n","\t\tFILE: Number of bytes read=144631\n","\t\tFILE: Number of bytes written=787073\n","\t\tFILE: Number of read operations=0\n","\t\tFILE: Number of large read operations=0\n","\t\tFILE: Number of write operations=0\n","\tMap-Reduce Framework\n","\t\tCombine input records=0\n","\t\tCombine output records=0\n","\t\tReduce input groups=5\n","\t\tReduce shuffle bytes=123\n","\t\tReduce input records=5\n","\t\tReduce output records=5\n","\t\tSpilled Records=5\n","\t\tShuffled Maps =1\n","\t\tFailed Shuffles=0\n","\t\tMerged Map outputs=1\n","\t\tGC time elapsed (ms)=0\n","\t\tTotal committed heap usage (bytes)=326107136\n","\tShuffle Errors\n","\t\tBAD_ID=0\n","\t\tCONNECTION=0\n","\t\tIO_ERROR=0\n","\t\tWRONG_LENGTH=0\n","\t\tWRONG_MAP=0\n","\t\tWRONG_REDUCE=0\n","\tFile Output Format Counters \n","\t\tBytes Written=131\n","2024-01-08 12:02:55,163 INFO mapred.LocalJobRunner: Finishing task: attempt_local1376991955_0001_r_000000_0\n","2024-01-08 12:02:55,163 INFO mapred.LocalJobRunner: reduce task executor complete.\n","2024-01-08 12:02:55,578 INFO mapreduce.Job:  map 100% reduce 100%\n","2024-01-08 12:02:55,578 INFO mapreduce.Job: Job job_local1376991955_0001 completed successfully\n","2024-01-08 12:02:55,604 INFO mapreduce.Job: Counters: 30\n","\tFile System Counters\n","\t\tFILE: Number of bytes read=288984\n","\t\tFILE: Number of bytes written=1573892\n","\t\tFILE: Number of read operations=0\n","\t\tFILE: Number of large read operations=0\n","\t\tFILE: Number of write operations=0\n","\tMap-Reduce Framework\n","\t\tMap input records=159\n","\t\tMap output records=159\n","\t\tMap output bytes=2389\n","\t\tMap output materialized bytes=123\n","\t\tInput split bytes=90\n","\t\tCombine input records=159\n","\t\tCombine output records=5\n","\t\tReduce input groups=5\n","\t\tReduce shuffle bytes=123\n","\t\tReduce input records=5\n","\t\tReduce output records=5\n","\t\tSpilled Records=10\n","\t\tShuffled Maps =1\n","\t\tFailed Shuffles=0\n","\t\tMerged Map outputs=1\n","\t\tGC time elapsed (ms)=0\n","\t\tTotal committed heap usage (bytes)=652214272\n","\tShuffle Errors\n","\t\tBAD_ID=0\n","\t\tCONNECTION=0\n","\t\tIO_ERROR=0\n","\t\tWRONG_LENGTH=0\n","\t\tWRONG_MAP=0\n","\t\tWRONG_REDUCE=0\n","\tFile Input Format Counters \n","\t\tBytes Read=2546\n","\tFile Output Format Counters \n","\t\tBytes Written=131\n","2024-01-08 12:02:55,604 INFO streaming.StreamJob: Output directory: ./salida2\n"]}]},{"cell_type":"code","source":["!cat ./salida2/*"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tb97aL5D-bse","executionInfo":{"status":"ok","timestamp":1704715737585,"user_tz":-60,"elapsed":283,"user":{"displayName":"Saioa Sada Allo","userId":"15281570099881323413"}},"outputId":"37eb82b4-0b5a-43d7-c54d-84b610d781dc"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Alice;Tienda1;98.75\t\n","Alice;Tienda2;20.0\t\n","Bob;Tienda1;20.25\t\n","Saioa;Eroski;34.87179487179487\t\n","Xabi;BM;33.17948717948718\t\n"]}]}]}